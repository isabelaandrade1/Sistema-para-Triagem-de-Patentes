# üß≠ README ‚Äî Similaridade Sem√¢ntica para Triagem de Patentes;

> **Objetivo**: dado o texto das **reivindica√ß√µes (claims)** de uma inven√ß√£o, o sistema retorna as **N patentes mais similares** por **similaridade de cosseno** entre **embeddings** (modelo multil√≠ngue). H√° tr√™s modos: **Local (JSON)**, **H√≠brido (Local + APIs externas/Lens)** e **Via API FastAPI**.

> **Importante**: a ferramenta **n√£o decide** concess√£o/validade. Ela **ranqueia** candidatos para **triagem**, **busca de anterioridade** e **apoio** √† an√°lise t√©cnico‚Äëjur√≠dica.

---

## √çndice

1. [Vis√£o geral](#vis√£o-geral)
2. [Arquitetura & T√©cnicas](#arquitetura--t√©cnicas)
3. [Pr√©‚Äërequisitos](#pr√©-requisitos)
4. [Instala√ß√£o](#instala√ß√£o)
5. [Configura√ß√£o (.env)](#configura√ß√£o-env)
6. [Estrutura do projeto](#estrutura-do-projeto)
7. [Base local (formato) & Regra de ouro](#base-local-formato--regra-de-ouro)
8. [Executando](#executando)
9. [Streamlit (UI)](#streamlit-ui)
10. [Modo H√≠brido (Local + Lens/API externa)](#modo-h√≠brido-local--lensapi-externa)
11. [Coleta de patentes com a Lens API](#coleta-de-patentes-com-a-lens-api)
12. [Usar **outro** banco (JSON/CSV/SQL) ou **outra** API](#usar-outro-banco-jsoncsvsql-ou-outra-api)
13. [Reprocessar embeddings](#reprocessar-embeddings)
14. [Testes automatizados](#testes-automatizados)
15. [Antes de publicar no GitHub](#antes-de-publicar-no-github)
16. [Solu√ß√£o de problemas](#solu√ß√£o-de-problemas)
17. [Links √∫teis](#links-√∫teis)
18. [Licen√ßa, contato & contribui√ß√µes](#licen√ßa-contato--contribui√ß√µes)

---

## Vis√£o geral

* **Modelo**: `sentence-transformers/paraphrase-multilingual-mpnet-base-v2` (dim=768, multil√≠ngue), com **L2‚Äënormaliza√ß√£o** dos vetores.
* **Similaridade**: **cosseno** (produto escalar entre vetores L2). Retorno em **0‚Äì1** (m√©tricas) e **%** (exibi√ß√£o).
* **Modos de uso**:

  * **Local (JSON)**: busca somente em `base_patentes.json`.
  * **H√≠brido (Local + Lens)**: agrega candidatos da Lens (ou outros provedores), re‚Äëembebe localmente e **re‚Äëranqueia**.
  * **Via API FastAPI**: cliente/servi√ßo externo consulta a API HTTP local.

---

## Arquitetura & T√©cnicas

```
claims ‚Üí limpeza ‚Üí embedding (mpnet, L2) ‚Üí
   ‚îú‚îÄ busca LOCAL (cosine Top‚ÄëK)
   ‚îú‚îÄ busca EXTERNA (Lens/‚Ä¶)* ‚Üí re‚Äërank local
   ‚îî‚îÄ mescla + dedup (id/lens_id) ‚Üí Top‚ÄëK final
* se LENS_API_KEY estiver configurada
```

**T√©cnicas/Ferramentas**

* **Transformers** (MPNet multilingue) via **Sentence‚ÄëTransformers**.
* **Embeddings** L2‚Äënormalizados ‚Üí cosseno por **produto escalar**.
* **H√≠brido**: *candidate generation* externo + *re‚Äëranking* local.
* **Avalia√ß√£o**: pares rotulados (0/1) para m√©tricas; ranking com P\@K/R\@K/nDCG\@K.
* **Stack**: Python, FastAPI, Streamlit, scikit‚Äëlearn, NumPy, Torch (CPU por padr√£o).

---

## Pr√©‚Äërequisitos

* **SO**: Windows 10/11 x64 (funciona tamb√©m em Linux/macOS).
* **Python**: 3.10 ou 3.11 (64‚Äëbits).
* **RAM**: 8 GB m√≠nimo (12‚Äì16 GB recomendado p/ bases maiores).
* **Disco**: 2‚Äì5 GB (modelo + cache + base). Bases grandes pedem mais.
* **Rede**: para baixar o modelo (1¬™ execu√ß√£o) e para modo **H√≠brido**.
* **Portas**: API `8000` (ajust√°vel), Streamlit `8512` (ajust√°vel).
* **GPU**: opcional. Projeto est√° configurado para **CPU**.

---

## Instala√ß√£o

> Abaixo, instala√ß√£o **CPU/Windows**. Em Linux/macOS, ajuste o √≠ndice do Torch conforme sua plataforma.

```bash
# 1) Ambiente virtual
python -m venv .venv
# Windows
. .venv\Scripts\activate
# Linux/macOS
# source .venv/bin/activate

# 2) Primeiro, instale o Torch (CPU) pelo √≠ndice da PyTorch
pip install --no-cache-dir --index-url https://download.pytorch.org/whl/cpu "torch==2.2.2"

# 3) Demais depend√™ncias (vers√µes est√°veis entre si)
pip install --no-cache-dir -r requirements.txt
```

**Vers√µes pinadas (sugest√£o)**

```
fastapi==0.111.0
starlette==0.37.2
uvicorn[standard]==0.30.1
streamlit==1.36.0
sentence-transformers==2.7.0
transformers==4.41.2
tokenizers==0.19.1
huggingface-hub==0.23.5
torch==2.2.2
numpy==1.26.4
scikit-learn==1.5.0
scipy==1.16.1
pandas==2.3.2
matplotlib==3.9.0
seaborn==0.13.2
nltk==3.9.1
langdetect==1.0.9
PyPDF2==3.0.1
python-dotenv==1.0.1
requests==2.32.3
pydantic==2.11.7
```

---

## Configura√ß√£o (.env)

Crie um arquivo `.env` **na raiz**:

```
# obrigat√≥rio para modo H√≠brido/Lens
LENS_API_KEY=SEU_TOKEN_DA_LENS
```

> Se n√£o existir `LENS_API_KEY`, o sistema funciona em **modo Local**.

---

## Estrutura do projeto

```
.
‚îú‚îÄ‚îÄ app.py                      # (opcional) servidor alternativo
‚îú‚îÄ‚îÄ main.py                     # FastAPI (endpoints /, /verificar, /buscar_similares)
‚îú‚îÄ‚îÄ streamlit_app.py            # UI (Local/H√≠brido/API)
‚îú‚îÄ‚îÄ processamento_texto.py      # limpeza + gerar_embedding (modelo mpnet, L2)
‚îú‚îÄ‚îÄ similaridade.py             # fun√ß√µes de score (0‚Äì1 e %)
‚îú‚îÄ‚îÄ buscar_similares.py         # CLI de busca local (JSON)
‚îú‚îÄ‚îÄ buscar_hibrido.py           # busca h√≠brida (Local + Lens/outros)
‚îú‚îÄ‚îÄ lens_api.py                 # chamadas √† Lens API (candidatos por claims)
‚îú‚îÄ‚îÄ coleta_patentes.py          # coleta/hidrata√ß√£o via Lens ‚Üí base_patentes.json
‚îú‚îÄ‚îÄ recalcular_embeddings.py    # reprocessa embeddings da base local
‚îú‚îÄ‚îÄ base_patentes.json          # base local (N itens, com embeddings L2)
‚îú‚îÄ‚îÄ tests/                      # su√≠te de testes (unittest)
‚îú‚îÄ‚îÄ relatorios/                 # sa√≠das de avalia√ß√£o (opcional)
‚îî‚îÄ‚îÄ README.md                   # este arquivo
```

---

## Base local (formato) & Regra de ouro

Arquivo **`base_patentes.json`** cont√©m **lista** de objetos no formatoArquivo: base_patentes.json ‚Äî cont√©m uma lista de objetos no formato abaixo. Baixar **`base_patentes.json`** em:
https://drive.google.com/file/d/144_DDZIJCmMNE82ZSqQF40R5IIkBxvwg/view?usp=sharing:

```json
{
  "lens_id": "...",
  "title": "...",
  "abstract": "...",
  "claims": "...",
  "description": "...",
  "embedding": [0.0123, -0.0456, ...]  
}
```

**Regra de ouro**: o campo `embedding` deve ser um **vetor de 768 floats L2‚Äënormalizado** das **claims** usando **o mesmo modelo** da consulta. Caso troque o modelo, **recalcule toda a base** (ver [Reprocessar embeddings](#reprocessar-embeddings)).

---

## Executando

### 1) API (FastAPI)

```bash
python main.py --port 8000
# ou (se preferir uvicorn direto)
# uvicorn main:app --host 127.0.0.1 --port 8000
```

**Endpoints**

* `GET /` ‚Üí status:

```json
{"status":"OK","itens_na_base":2250,"modo_hibrido_disponivel":true}
```

* `POST /buscar_similares` (usa apenas `claims`):

```json
{ "claims": "texto das claims...", "top_k": 10 }
```

* `POST /verificar` (payload completo; prioriza `claims` se houver):

```json
{ "titulo":"...", "resumo":"...", "claims":"...", "descricao":"...", "top_k": 10 }
```

**Resposta (exemplo)**

```json
{
  "resultados": [
    {
      "lens_id": "140-...-70X",
      "title": "...",
      "claims": "trecho...",
      "link": "https://www.lens.org/lens/patent/140-...-70X",
      "score": 0.8245,
      "similaridade_percentual": 82.45,
      "fonte": "local"
    }
  ]
}
```

### 2) CLI local

```bash
python buscar_similares.py
# cole o texto das claims quando solicitado
```

---

## Streamlit (UI)

```bash
streamlit run streamlit_app.py --server.port 8512
```

* **Local (JSON)**: consulta apenas `base_patentes.json`.
* **H√≠brido (Local + Lens)**: requer `LENS_API_KEY` no `.env`.
* **Via API FastAPI**: a UI chama os endpoints HTTP locais.

---

## Modo H√≠brido (Local + Lens/API externa)

1. Gere o **embedding L2** da **consulta** (claims) localmente.
2. Busque **candidatos externos** (Lens/outros provedores).
3. Para cada candidato, obtenha texto relevante (idealmente **claims**), gere **embedding L2** **local** e **re‚Äëranqueie** junto com a base local.
4. **Mescle** resultados (dedup por `lens_id`/`id`) e retorne **Top‚ÄëK**.

> Re‚Äëranquear localmente garante que todos os vetores estejam **no mesmo espa√ßo** (mesmo modelo), evitando escalas incompat√≠veis.

---

## Coleta de patentes com a Lens API

### Solicitar acesso

1. Crie conta em **lens.org** e acesse a √°rea de **API**.
2. Solicite um **API Key** (uso: pesquisa/educacional/prot√≥tipo).
3. Configure o `.env`:

```
LENS_API_KEY=SEU_TOKEN_DA_LENS
```

> Pol√≠ticas e limites podem mudar. Consulte a documenta√ß√£o/painel da Lens.

### Rodar a coleta (script pronto)

```bash
python coleta_patentes.py
```

O script:

* Faz *search* com `simple_query_string` em `claims^3, description^2, abstract` (termos aleat√≥rios p/ diversidade);
* Busca detalhes por `lens_id`;
* **Limpa** o texto e gera **embedding L2** das **claims**;
* Persiste incrementalmente em `base_patentes.json` (checkpoint);
* Respeita `429/Retry-After`.

Par√¢metros no arquivo:

* `TOTAL_DESEJADO`, `TAMANHO_PAGINA`, `TERMOS_ALEATORIOS`.

> Se interromper, roda novamente e o script **retoma** sem duplicar.

---

## Usar **outro** banco (JSON/CSV/SQL) ou **outra** API

Voc√™ **n√£o** est√° preso ao `base_patentes.json` original.

### A) Outro arquivo **JSON**

1. Converta sua base para o **formato** da se√ß√£o [Base local](#base-local-formato--regra-de-ouro).
2. Salve como `base_meu_bd.json`.
3. Aponte o caminho no c√≥digo:

   * `main.py`: `BASE_PATH = "base_meu_bd.json"`
   * `buscar_similares.py`: `CAMINHO_ARQUIVO = "base_meu_bd.json"`

### B) **CSV/SQL** ‚Üí JSON (exemplo de adaptador)

```python
# adapters/csv_para_json.py
import pandas as pd, json
from processamento_texto import gerar_embedding

def csv_para_json(caminho_csv, saida_json):
    df = pd.read_csv(caminho_csv)
    itens = []
    for _, r in df.iterrows():
        claims = str(r.get('claims', '') or '').strip()
        if not claims:
            continue
        emb = gerar_embedding(texto_claims=claims, normalize=True).tolist()
        itens.append({
            "lens_id": str(r.get('id', '')),
            "title": str(r.get('title', '')),
            "abstract": str(r.get('abstract', '')),
            "claims": claims,
            "description": str(r.get('description', '')),
            "embedding": emb
        })
    with open(saida_json, 'w', encoding='utf-8') as f:
        json.dump(itens, f, ensure_ascii=False, indent=2)

if __name__ == "__main__":
    csv_para_json("minha_base.csv", "base_patentes.json")
```

> Para **SQL**, leia com pandas/SQLAlchemy, gere os embeddings e grave o JSON no mesmo formato.

### C) **Outra API externa** (al√©m da Lens)

Crie um provedor que retorne candidatos por **claims** e re‚Äëranqueie localmente:

```python
# providers/meu_provedor.py (exemplo)
import os, requests
from dotenv import load_dotenv
load_dotenv()
API_KEY = os.getenv("MEU_API_KEY")

def candidatos_por_claims(texto_claims: str, top_n: int = 30):
    # 1) chamar a API e coletar candidatos (id, title, claims/trecho, link)
    # 2) normalizar e retornar lista: {"id":"...","title":"...","claims":"...","link":"..."}
    return []
```

Registrar no h√≠brido (`buscar_hibrido.py`):

```python
from providers.meu_provedor import candidatos_por_claims as prov_meu
PROVEDORES = [
    ("lens", candidatos_por_claims),
    ("meu",  prov_meu),
]
```

> Gere o **embedding L2 local** para cada candidato antes do re‚Äëranking.

**Aten√ß√£o**: trocou de **modelo** de embedding? Recalcule **toda a base**.

---

## Reprocessar embeddings

Use quando alterar **modelo** ou **pr√©‚Äëprocessamento**:

```bash
python recalcular_embeddings.py
```

O script abre `base_patentes.json`, recalcula `embedding` das claims (**L2**) e salva.

---

## Testes automatizados

Rodar todos os testes:

```bash
# da raiz do projeto
python -m unittest discover -s tests -p "test_*.py" -v
```

Se seu c√≥digo estiver em `src/`, exponha o caminho:

```powershell
# Windows (PowerShell)
$env:PYTHONPATH = "$PWD\src"
python -m unittest discover -s tests -p "test_*.py" -v
```

> Na primeira execu√ß√£o, o modelo ser√° baixado (testes de embedding podem demorar um pouco). As pr√≥ximas rodam mais r√°pido.

---

## Antes de publicar no GitHub

Remova dados sens√≠veis/pesados e segredos:

```bash
# apagar base local
# Windows
del base_patentes.json 2>$null
# Linux/macOS
rm -f base_patentes.json
```

`.gitignore` sugerido:

```
.env
base_patentes.json
relatorios/
data/
*.jsonl
*.parquet
*.csv
```

> Se algo j√° foi versionado por engano, use `git rm --cached <arquivo>` e fa√ßa novo commit (ou ferramentas como `git filter-repo` para limpar hist√≥rico).

---

## Solu√ß√£o de problemas

* **Porta ocupada**: mude a porta (UI `--server.port`, API `--port`). Para matar processo (Windows PowerShell):

  ```powershell
  Get-Process -Id (Get-NetTCPConnection -LocalPort 8000).OwningProcess | Stop-Process -Force
  ```
* **NumPy/Torch**: use `numpy==1.26.4` com `torch==2.2.2`. Evite `numpy 2.x` com libs que foram compiladas p/ 1.x.
* **Transformers/Tokenizers**: `transformers 4.41.x` requer `tokenizers >=0.19,<0.20` ‚Üí use `0.19.1`.
* **Modelo n√£o baixa**: verifique rede/proxy; rode `pip cache purge` e tente novamente.
* **Base vazia**: gere `base_patentes.json` (coleta Lens ou CSV/SQL ‚Üí JSON).

---

## Links √∫teis

* Modelo (Hugging Face): [https://huggingface.co/sentence-transformers/paraphrase-multilingual-mpnet-base-v2](https://huggingface.co/sentence-transformers/paraphrase-multilingual-mpnet-base-v2)
* Sentence‚ÄëTransformers: [https://www.sbert.net/](https://www.sbert.net/)
* Transformers: [https://huggingface.co/docs/transformers](https://huggingface.co/docs/transformers)
* FastAPI: [https://fastapi.tiangolo.com/](https://fastapi.tiangolo.com/)
* Streamlit: [https://docs.streamlit.io/](https://docs.streamlit.io/)
* Lens API: [https://docs.lens.org/](https://docs.lens.org/)

---

## Licen√ßa, contato & contribui√ß√µes
* **Licen√ßa**: MIT ‚Äî uso livre para fins acad√™micos, educacionais e prototipagem.
* **Contato**: [isabela.andradeaguiar1@gmail.com](mailto:isabela.andradeaguiar1@gmail.com)
* **Contribuir**: fa√ßa *fork* ‚Üí *branch* (`feat/minha-feature`) ‚Üí *PR* com escopo claro e, se poss√≠vel, testes.