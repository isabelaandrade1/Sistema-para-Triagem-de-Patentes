# üß≠ README ‚Äî Similaridade Sem√¢ntica para Triagem de Patentes;

## 1) O que √©

\*\*Busca sem√¢ntica Top‚ÄëK de patentes a partir das suas \*\****claims***. Voc√™ cola o texto das reivindica√ß√µes e recebe as **N patentes mais similares** (cosine) ‚Äî para triagem, busca de anterioridade e apoio √† an√°lise t√©cnica.

> O sistema **n√£o decide** concess√£o; ele **ranqueia** candidatos por proximidade sem√¢ntica.

---

## 2) TL;DR

* **Modelo**: `paraphrase-multilingual-mpnet-base-v2` (768d, L2) ‚Äî multil√≠ngue.
* **Modos**: Local (JSON) ¬∑ H√≠brido (Local + Lens) ¬∑ Via API FastAPI.
* **Base**: local (JSON), CSV/SQL convertido ou **APIs externas** (Lens, etc.).
* **Rodar r√°pido**:

  ```bash
  # venv + depend√™ncias (Windows/CPU)
  python -m venv .venv && .venv\Scripts\activate
  pip install --no-cache-dir --index-url https://download.pytorch.org/whl/cpu "torch==2.2.2"
  pip install --no-cache-dir -r requirements.txt

  # backend (API)
  python main.py --port 8000

  # UI (opcional)
  streamlit run streamlit_app.py --server.port 8512
  ```

---

## 3) Como funciona (resumo)

```
claims ‚Üí limpeza ‚Üí embedding (mpnet) ‚Üí
   ‚îú‚îÄ busca LOCAL (base_patentes.json)
   ‚îú‚îÄ busca EXTERNA (Lens)* ‚Üí re‚Äërank local
   ‚îî‚îÄ mescla + dedup (lens_id) ‚Üí Top‚ÄëK
* se LENS_API_KEY estiver configurada
```

## 4) Metodologia (reprodut√≠vel / passo a passo)

> Detalhes para qualquer pessoa reproduzir coleta, indexa√ß√£o, busca e avalia√ß√£o.

### 4.1 Ambiente e vers√µes

* **Python**: 3.10 ou 3.11 (x64)
* **Stack fixado**: `torch==2.2.2`, `numpy==1.26.4`, `transformers==4.41.2`, `tokenizers==0.19.1`, `huggingface-hub==0.23.5`, `sentence-transformers==2.7.0`, `fastapi==0.111.0`, `streamlit==1.36.0`.
* **Seeds**: 42 para `random`, `numpy` e `torch`.

Instala√ß√£o (CPU, gen√©rica):

```bash
python -m venv .venv
python -m pip install --upgrade pip
pip install --no-cache-dir --index-url https://download.pytorch.org/whl/cpu torch==2.2.2
pip install --no-cache-dir -r requirements.txt
```

### 4.2 Pr√©-processamento de texto

* Min√∫sculas, remo√ß√£o de URLs, manter letras/d√≠gitos/acentos, colapsar espa√ßos.
* Detec√ß√£o de idioma e *stopwords* multil√≠ngues (opcional).
* Implementa√ß√£o em `processamento_texto.py` (`limpar_texto`, `gerar_embedding`).

### 4.3 Embeddings (modelo e normaliza√ß√£o)

* Modelo: `sentence-transformers/paraphrase-multilingual-mpnet-base-v2` (dim=768).
* `encode(texto, convert_to_numpy=True)`.
* L2: `v = e / ||e||2` (se norma>0). Persistir como lista de 768 floats.
* Comprimento: truncamento/padding interno do Sentence-Transformers; ajuste com `model.max_seq_length` se necess√°rio.

### 4.4 Constru√ß√£o da base local

* **Via CSV/SQL** ‚Üí converter para JSON (chaves: `lens_id/title/abstract/claims/description`), gerar embedding das claims e salvar em `base_patentes.json`.
* **Via Lens (opcional)** ‚Üí `.env` com `LENS_API_KEY` e `python coleta_patentes.py`.
* Busca na Lens: `simple_query_string` em `claims^3, description^2, abstract`; respeitar 429/Retry-After; descartar itens sem claims.

**Esquema JSON do item**

```json
{
  "lens_id":"...",
  "title":"...",
  "abstract":"...",
  "claims":"...",
  "description":"...",
  "embedding":[0.0123, -0.0456, 0.001, ...]
}
```

### 4.5 Busca local (cosine Top-K)

* Carregar matriz `E` (n√ó768) com embeddings L2; consulta `q` (768, L2).
* Cosine: `sims = E @ q`; selecionar Top‚ÄëK; ordenar decrescente; retornar metadados + `score` (0‚Äì1) e `%`.
* Implementa√ß√µes: `main.py` (/verificar, /buscar\_similares) e `buscar_similares.py` (CLI local).

### 4.6 Busca h√≠brida (Local + API externa)

* Se `.env` tiver `LENS_API_KEY`, chamar `lens_api.candidatos_por_claims(texto, top_n‚âà3K)`.
* Para cada candidato, obter `claims`/trecho, gerar embedding L2 local; **mesclar** (dedup por `lens_id/id`), recomputar `sims` e **re‚Äëranquear**; devolver Top‚ÄëK √∫nico.

### 4.7 Avalia√ß√£o (pares rotulados ‚Äî protocolo)

* **Amostragem**: estratifique por jurisdi√ß√£o/ano/IPC (documente no artigo).
* **Rotuladores**: ‚â•2 avaliadores de PI; **adjudica√ß√£o** por terceiro em caso de empate.
* **Concord√¢ncia**: reporte **Cohen‚Äôs Œ∫**/**Krippendorff‚Äôs Œ±**.
* **M√©tricas**: Accuracy, Macro‚ÄëF1, MCC, Kappa, ROC‚ÄëAUC, AP; para ranking: P\@10, R\@10, nDCG\@10.
* **Scripts**: `avaliar_pares_manual.py`, `avaliar_pares_rotulados_sem_zona.py`, `avaliar_metricas.py`.

Exemplo:

```bash
python avaliar_metricas.py --arquivo rotulos.jsonl --k 10
```

### 4.8 Execu√ß√£o ponta‚Äëa‚Äëponta

```bash
# gerar/atualizar base (opcional)
python coleta_patentes.py
# subir API
python main.py --port 8000
# testar
curl -s http://127.0.0.1:8000/
curl -s -X POST http://127.0.0.1:8000/buscar_similares -H "Content-Type: application/json" -d '{"claims":"Texto das claims","top_k":10}'
# UI
streamlit run streamlit_app.py --server.port 8512
```

---

## 4) Endpoints principais (API)

* **GET /** ‚Üí status: itens na base e se h√≠brido est√° dispon√≠vel.
* **POST /buscar\_similares**

  ```json
  { "claims": "texto das claims‚Ä¶", "top_k": 10 }
  ```
* **POST /verificar** (payload completo; usa `claims` se existir)

  ```json
  { "titulo":"...", "resumo":"...", "claims":"...", "descricao":"...", "top_k": 10 }
  ```

**Resposta (exemplo):**

```json
{
  "resultados": [
    {"lens_id":"140-...-70X","title":"...","link":"https://www.lens.org/lens/patent/140-...-70X","score":0.8245,"similaridade_percentual":82.45,"fonte":"local"}
  ]
}
```

---

## 5) Base local (formato e regra de ouro)

Arquivo **`base_patentes.json`** (lista de objetos):

```json
{
  "lens_id":"...",
  "title":"...",
  "abstract":"...",
  "claims":"...",
  "description":"...",
  "embedding":[0.0123, -0.0456, ...]  // vetor 768 **L2-normalizado** das claims
}
```

**Sempre salve o embedding das *********************************claims********************************* j√° L2‚Äënormalizado.**

---

## 6) H√≠brido (Local + Lens) ‚Äî opcional

1. Crie `.env` na raiz:

   ```
   LENS_API_KEY=SEU_TOKEN_DA_LENS
   ```
2. Mantenha `lens_api.py` e `buscar_hibrido.py` na raiz. O servidor tenta h√≠brido e faz **fallback** para Local se falhar.

---

## 7) Requisitos (matriz est√°vel ‚Äî Windows/CPU)

* `torch==2.2.2`  +  `numpy==1.26.4`
* `transformers==4.41.2`  +  `tokenizers==0.19.1`  +  `huggingface-hub==0.23.5`
* `sentence-transformers==2.7.0`
* `fastapi==0.111.0` ¬∑ `starlette==0.37.2` ¬∑ `uvicorn[standard]==0.30.1`
* `streamlit==1.36.0` ¬∑ `scikit-learn==1.5.0`

> Instale o Torch (CPU) **antes** do restante, pelo √≠ndice da PyTorch (comando acima).
> **Arquivo principal de instala√ß√£o**: use `requirements.txt` deste reposit√≥rio para garantir compatibilidade.

---

## 8) Como gerar a base rapidamente

* **CSV/SQL ‚Üí JSON**: extraia `id/title/claims/abstract/description`, calcule `embedding` (claims) com `processamento_texto.gerar_embedding(..., normalize=True)` e salve no formato do item 5.
* **Via Lens**: `python coleta_patentes.py` (respeita `Retry-After`).
* **Reprocessar** embeddings: `python recalcular_embeddings.py`.

---

## 8.1) Antes de publicar no GitHub (limpar dados locais)

Antes de subir o reposit√≥rio, **remova qualquer dado privado ou pesado**:

* Apague a base local e arquivos derivados:

  ```bash
  # Windows (PowerShell)
  del base_patentes.json 2>$null
  # Linux/macOS
  rm -f base_patentes.json
  ```
* Opcional: mantenha **apenas um exemplo m√≠nimo** (ex.: `base_20_patentes.json`) para demonstra√ß√£o, mas **n√£o o use em produ√ß√£o**. No c√≥digo, altere `BASE_PATH`/`CAMINHO_ARQUIVO` para esse arquivo de amostra quando quiser rodar o projeto sem dados reais.
* Garanta que segredos e dumps **n√£o** sejam versionados. Sugest√£o de `.gitignore`:

  ```gitignore
  # Segredos
  .env

  # Bases e artefatos locais
  base_patentes.json
  data/
  relatorios/
  *.jsonl
  *.parquet
  *.csv
  ```

> Dica: se voc√™ j√° versionou algum desses arquivos por engano, remova do hist√≥rico com `git rm --cached <arquivo>` e fa√ßa um novo commit.

---

## 8.2) Como solicitar acesso √† **Lens API** (para busca/coleta externa)

1. **Crie uma conta** em *lens.org* (gratuita) e entre na √°rea de **desenvolvedores / API**.
2. **Solicite uma chave de API** (token Bearer). A Lens pode exigir um formul√°rio simples com o **uso pretendido** (pesquisa/ensino/prot√≥tipo) e **limites** aceitos de uso.
3. Ap√≥s aprovado, voc√™ receber√° um **API key/token**. Guarde-o em local seguro e **n√£o versionado**.
4. Configure seu token no arquivo `.env` na raiz do projeto:

   ```env
   LENS_API_KEY=SEU_TOKEN_DA_LENS
   ```

> Observa√ß√£o: a pol√≠tica da Lens (modelos de acesso, limites, rotas) pode mudar ao longo do tempo. Verifique a documenta√ß√£o oficial e o painel da sua conta ao solicitar o acesso.

**Modelo de e‚Äëmail (caso precise solicitar por suporte):**

```
Assunto: Solicita√ß√£o de acesso √† Lens Patent API

Ol√°, 
Sou [Seu Nome], [Institui√ß√£o/Empresa]. Estou desenvolvendo um prot√≥tipo acad√™mico de triagem de patentes por similaridade sem√¢ntica e gostaria de solicitar acesso √† Lens Patent API (apenas leitura), com uso limitado para pesquisa. 
Obrigado!
[Seu contato]
```

---

## 8.3) Coletar patentes via Lens (script incluso)

Com a chave configurada, use o script `coleta_patentes.py` para **hidratar** a base local:

```bash
# ativa o ambiente e roda a coleta
python coleta_patentes.py
```

O script:

* Faz buscas paginadas usando termos gen√©ricos aleat√≥rios (para diversidade),
* Busca detalhes por `lens_id`,
* Limpa texto e **gera embedding L2** das *claims*,
* Salva/atualiza `base_patentes.json` continuamente (checkpoint a cada \~100 itens),
* Respeita `429/Retry-After` com espera autom√°tica.

**Par√¢metros edit√°veis no arquivo** (valores padr√£o j√° no c√≥digo):

* `TOTAL_DESEJADO`: volume alvo de patentes (ex.: `10000`).
* `TAMANHO_PAGINA`: tamanho do lote por requisi√ß√£o (ex.: `50`).
* `TERMOS_ALEATORIOS`: lista de termos usados na *simple\_query\_string*.

> Se a execu√ß√£o for interrompida, o script **retoma** a partir do que j√° existe em `base_patentes.json`.

**Re-hidrata√ß√£o / reprocessamento**

* Caso mude o **modelo** de embedding, rode `recalcular_embeddings.py` para recalcular os vetores a partir das *claims* j√° armazenadas.

---

## 9) Streamlit (UI)

* Modo **Local (JSON)**, **H√≠brido** (se `.env` presente) ou **Via API FastAPI** (aponta para `http://127.0.0.1:8000`).
* Mostra **Top‚ÄëK** com link da Lens e trecho das claims.

---

## 10) Troubleshooting (r√°pido)

* **Porta ocupada**: mude `--server.port` (UI) ou `--port` (API).
* **NumPy/Torch**: use `numpy==1.26.4` com `torch==2.2.2`.
* **Tokenizers/Transformers**: `transformers 4.41.x` requer `tokenizers >=0.19,<0.20` ‚Üí use `0.19.1`.
* **Base vazia**: gere `base_patentes.json` (item 8).

---

## 11) Licen√ßa & aviso

* **Licen√ßa**: defina MIT/Apache‚Äë2.0.
* **Aviso**: ferramenta de apoio √† triagem; n√£o substitui an√°lise t√©cnica/jur√≠dica.

---

## 12) Usar outro banco de dados (local ou API)

Voc√™ **n√£o** est√° preso ao `base_patentes.json`. Qualquer fonte pode ser usada, desde que entregue **texto de claims** e, idealmente, **embeddings L2** no mesmo espa√ßo do modelo.

### A) Outro **arquivo local** (JSON)

1. Converta seu banco para o **esquema do item 5** (chaves e embedding L2 das *claims*).
2. Salve como `base_meu_bd.json`.
3. Altere o caminho no servidor/API:

   * Em `main.py`, troque:

     ```python
     BASE_PATH = "base_patentes.json"  # ‚Üí "base_meu_bd.json"
     ```
   * (Se usar busca direta local no app) Em `buscar_similares.py`, troque `CAMINHO_ARQUIVO` para o novo JSON.

> Recomenda-se **exportar para JSON** no formato do item 5. √â simples, r√°pido e reaproveita todo o pipeline.

### B) **CSV/SQL** ‚Üí JSON (convers√£o r√°pida)

Use um adaptador simples para transformar suas tabelas em JSON compat√≠vel:

```python
# adapters/csv_para_json.py (exemplo)
import pandas as pd, json
from processamento_texto import gerar_embedding

def csv_para_json(caminho_csv, saida_json):
    df = pd.read_csv(caminho_csv)
    itens = []
    for _, r in df.iterrows():
        claims = str(r.get('claims', '') or '').strip()
        if not claims:
            continue
        emb = gerar_embedding(texto_claims=claims, normalize=True).tolist()
        itens.append({
            "lens_id": str(r.get('id', '')),
            "title": r.get('title', ''),
            "abstract": r.get('abstract', ''),
            "claims": claims,
            "description": r.get('description', ''),
            "embedding": emb
        })
    with open(saida_json, 'w', encoding='utf-8') as f:
        json.dump(itens, f, ensure_ascii=False, indent=2)
```

Depois aponte `BASE_PATH`/`CAMINHO_ARQUIVO` para o JSON gerado.

### C) **Outra API externa** (al√©m da Lens)

Adapte um provedor que retorne **candidatos por claims**, depois **re‚Äëranqueie localmente**:

1. Crie um m√≥dulo do provedor, e.g. `providers/meu_provedor.py`:

   ```python
   # providers/meu_provedor.py (exemplo)
   import os, requests
   from dotenv import load_dotenv
   load_dotenv()
   API_KEY = os.getenv("MEU_API_KEY")

   def candidatos_por_claims(texto_claims: str, top_n: int = 30):
       # 1) chame a API e traga candidatos (id, t√≠tulo, claims/trecho, link)
       # 2) normalize campos e retorne lista de dicts compat√≠veis
       # Estrutura m√≠nima por item: {"id":"...","title":"...","claims":"...","link":"..."}
       return []
   ```
2. Inclua no **h√≠brido** (`buscar_hibrido.py`):

   ```python
   from providers.meu_provedor import candidatos_por_claims as prov_meu

   PROVEDORES = [
       ("lens", candidatos_por_claims),   # j√° existente
       ("meu",  prov_meu),                # novo provedor
   ]

   todos = []
   for nome, fn in PROVEDORES:
       cands = fn(texto_claims, top_n=top_k*3)
       # calcule embedding localmente e anexe ao pool
       for c in cands:
           emb = gerar_embedding(texto_claims=c.get("claims",""), normalize=True)
           todos.append({
               "lens_id": c.get("id",""),
               "title": c.get("title",""),
               "claims": c.get("claims",""),
               "link": c.get("link",""),
               "embedding": emb.tolist(),
               "fonte": "externa"
           })
   # depois: dedup por lens_id/id, cosine com a query e Top‚ÄëK
   ```
3. Configure a chave no `.env` (ex.: `MEU_API_KEY=...`).

> Dica: se a API externa n√£o fornece **claims** completas, use **resumo/trecho** relevante. O re‚Äëranqueamento local via embedding alinha as escalas.

### D) Observa√ß√µes importantes

* **Consist√™ncia de espa√ßo vetorial**: se trocar o **modelo de embedding**, **recalcule toda a base** para o mesmo espa√ßo (caso contr√°rio, cosine n√£o √© compar√°vel).
* **Tamanho da base**: para bases muito grandes, considere indexadores ANN (FAISS/HNSW) no futuro.
* **Chaves/seguran√ßa**: mantenha credenciais apenas no back‚Äëend e use HTTPS em produ√ß√£o.

---

## 13) Pr√©‚Äërequisitos (ambiente)

* **Python**: 3.10 ou 3.11 recomendados (Windows 10/11 x64). Funciona em Linux/macOS; ajuste instala√ß√£o do Torch conforme plataforma.
* **RAM**: 8 GB m√≠nimo (12‚Äì16 GB recomendado) para trabalhar com bases m√©dias.
* **Disco**: 2‚Äì5 GB livres (modelos + cache + base local). Bases grandes exigem mais.
* **Rede**: necess√°ria para baixar o modelo na 1¬™ execu√ß√£o e para o modo **H√≠brido** (Lens ou outras APIs).
* **Portas**: API padr√£o `8000`, Streamlit `8512` (ajust√°veis).
* **GPU**: opcional; o projeto foi configurado para **CPU**. Para GPU, instale a variante adequada do Torch e teste as vers√µes do stack.

---

## 14) Testes r√°pidos / verifica√ß√£o

### 14.0 Rodar toda a su√≠te

> Execute a partir da **raiz do projeto**. Se seu c√≥digo est√° em `src/`, defina o `PYTHONPATH`.

**Windows (PowerShell):**

```powershell
# ativar venv
. .\.venv\Scripts\activate
# expor src para os testes
$env:PYTHONPATH = "$PWD\src"
# rodar todos os testes em tests/
python -m unittest discover -s tests -p "test_*.py" -v
```

> Dica: na 1¬™ execu√ß√£o o modelo √© baixado; a segunda rodada fica bem mais r√°pida.
> Se n√£o quiser mexer em `PYTHONPATH`, no topo de cada teste voc√™ pode inserir:
>
> ```python
> import os, sys
> ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
> SRC  = os.path.join(ROOT, "src")
> for p in (ROOT, SRC):
>     sys.path.insert(0, p) if p not in sys.path else None
> ```

### 14.1 Sanidade do modelo

```bash
python - << 'PY'
from sentence_transformers import SentenceTransformer
import numpy as np
m = SentenceTransformer("paraphrase-multilingual-mpnet-base-v2")
e = m.encode("teste r√°pido", convert_to_numpy=True)
print("shape:", e.shape, "norm:", float(np.linalg.norm(e)))
PY
```

Sa√≠da esperada: `shape: (768,)` e `norm > 0`.

### 14.2 API online

```bash
# subir API
python main.py --port 8000
# status
curl -s http://127.0.0.1:8000/
# busca
curl -s -X POST http://127.0.0.1:8000/buscar_similares \
  -H "Content-Type: application/json" \
  -d '{"claims":"Um sistema para ...","top_k":10}'
```

> Se seu `main.py` estiver em `src/` e voc√™ preferir usar uvicorn direto:
> `uvicorn src.main:app --host 127.0.0.1 --port 8000`

### 14.3 UI (Streamlit)

```bash
streamlit run streamlit_app.py --server.port 8512
```

Escolha **Local**, **H√≠brido** (se `.env`) ou **Via API FastAPI**.

### 14.4 Scripts de avalia√ß√£o (se aplic√°vel)

* `similaridade.py`: fun√ß√µes de score (0‚Äì1 para m√©tricas; % para exibi√ß√£o).
* `avaliar_metricas.py`: gera m√©tricas agregadas (precis√£o\@K, etc.).
* `avaliar_pares_manual.py` / `avaliar_pares_rotulados_sem_zona.py`: avaliam pares rotulados.

Exemplo:

```bash
python avaliar_metricas.py --arquivo rotulos.jsonl --k 10
```

> Observa√ß√£o: os testes e avalia√ß√µes usam **apenas base local**; n√£o chamam a Lens (sem rede).

---

## 15) Exemplo visual

Adicione imagens na pasta `assets/` e referencie aqui:

**UI (Streamlit)**

# üß≠ README ‚Äî IA de Triagem de Patentes (vers√£o enxuta)

## 1) O que √©

\*\*Busca sem√¢ntica Top‚ÄëK de patentes a partir das suas \*\****claims***. Voc√™ cola o texto das reivindica√ß√µes e recebe as **N patentes mais similares** (cosine) ‚Äî para triagem, busca de anterioridade e apoio √† an√°lise t√©cnica.

> O sistema **n√£o decide** concess√£o; ele **ranqueia** candidatos por proximidade sem√¢ntica.

---

## 2) TL;DR

* **Modelo**: `paraphrase-multilingual-mpnet-base-v2` (768d, L2) ‚Äî multil√≠ngue.
* **Modos**: Local (JSON) ¬∑ H√≠brido (Local + Lens) ¬∑ Via API FastAPI.
* **Base**: local (JSON), CSV/SQL convertido ou **APIs externas** (Lens, etc.).
* **Rodar r√°pido**:

  ```
  # venv + depend√™ncias (Windows/CPU)
  python -m venv .venv && .venv\Scripts\activate
  pip install --no-cache-dir --index-url https://download.pytorch.org/whl/cpu "torch==2.2.2"
  pip install --no-cache-dir -r requirements.txt

  # backend (API)
  python main.py --port 8000

  # UI (opcional)
  streamlit run streamlit_app.py --server.port 8512

  ```

---

## 3) Como funciona (resumo)

```
claims ‚Üí limpeza ‚Üí embedding (mpnet) ‚Üí
   ‚îú‚îÄ busca LOCAL (base_patentes.json)
   ‚îú‚îÄ busca EXTERNA (Lens)* ‚Üí re‚Äërank local
   ‚îî‚îÄ mescla + dedup (lens_id) ‚Üí Top‚ÄëK
* se LENS_API_KEY estiver configurada

```

## 4) Metodologia (reprodut√≠vel / passo a passo)

> Detalhes para qualquer pessoa reproduzir coleta, indexa√ß√£o, busca e avalia√ß√£o.

### 4.1 Ambiente e vers√µes

* **Python**: 3.10 ou 3.11 (x64)
* **Stack fixado**: `torch==2.2.2`, `numpy==1.26.4`, `transformers==4.41.2`, `tokenizers==0.19.1`, `huggingface-hub==0.23.5`, `sentence-transformers==2.7.0`, `fastapi==0.111.0`, `streamlit==1.36.0`.
* **Seeds**: 42 para `random`, `numpy` e `torch`.

Instala√ß√£o (CPU, gen√©rica):

```
python -m venv .venv
python -m pip install --upgrade pip
pip install --no-cache-dir --index-url https://download.pytorch.org/whl/cpu torch==2.2.2
pip install --no-cache-dir -r requirements.txt

```

### 4.2 Pr√©-processamento de texto

* Min√∫sculas, remo√ß√£o de URLs, manter letras/d√≠gitos/acentos, colapsar espa√ßos.
* Detec√ß√£o de idioma e *stopwords* multil√≠ngues (opcional).
* Implementa√ß√£o em `processamento_texto.py` (`limpar_texto`, `gerar_embedding`).

### 4.3 Embeddings (modelo e normaliza√ß√£o)

* Modelo: `sentence-transformers/paraphrase-multilingual-mpnet-base-v2` (dim=768).
* `encode(texto, convert_to_numpy=True)`.
* L2: `v = e / ||e||2` (se norma>0). Persistir como lista de 768 floats.
* Comprimento: truncamento/padding interno do Sentence-Transformers; ajuste com `model.max_seq_length` se necess√°rio.

### 4.4 Constru√ß√£o da base local

* **Via CSV/SQL** ‚Üí converter para JSON (chaves: `lens_id/title/abstract/claims/description`), gerar embedding das claims e salvar em `base_patentes.json`.
* **Via Lens (opcional)** ‚Üí `.env` com `LENS_API_KEY` e `python coleta_patentes.py`.
* Busca na Lens: `simple_query_string` em `claims^3, description^2, abstract`; respeitar 429/Retry-After; descartar itens sem claims.

**Esquema JSON do item**

```
{
  "lens_id":"...",
  "title":"...",
  "abstract":"...",
  "claims":"...",
  "description":"...",
  "embedding":[0.0123, -0.0456, 0.001, ...]
}

```

### 4.5 Busca local (cosine Top-K)

* Carregar matriz `E` (n√ó768) com embeddings L2; consulta `q` (768, L2).
* Cosine: `sims = E @ q`; selecionar Top‚ÄëK; ordenar decrescente; retornar metadados + `score` (0‚Äì1) e `%`.
* Implementa√ß√µes: `main.py` (/verificar, /buscar\_similares) e `buscar_similares.py` (CLI local).

### 4.6 Busca h√≠brida (Local + API externa)

* Se `.env` tiver `LENS_API_KEY`, chamar `lens_api.candidatos_por_claims(texto, top_n‚âà3K)`.
* Para cada candidato, obter `claims`/trecho, gerar embedding L2 local; **mesclar** (dedup por `lens_id/id`), recomputar `sims` e **re‚Äëranquear**; devolver Top‚ÄëK √∫nico.

### 4.7 Avalia√ß√£o (pares rotulados ‚Äî protocolo)

* **Amostragem**: estratifique por jurisdi√ß√£o/ano/IPC (documente no artigo).
* **Rotuladores**: ‚â•2 avaliadores de PI; **adjudica√ß√£o** por terceiro em caso de empate.
* **Concord√¢ncia**: reporte **Cohen‚Äôs Œ∫**/**Krippendorff‚Äôs Œ±**.
* **M√©tricas**: Accuracy, Macro‚ÄëF1, MCC, Kappa, ROC‚ÄëAUC, AP; para ranking: P\@10, R\@10, nDCG\@10.
* **Scripts**: `avaliar_pares_manual.py`, `avaliar_pares_rotulados_sem_zona.py`, `avaliar_metricas.py`.

Exemplo:

```
python avaliar_metricas.py --arquivo rotulos.jsonl --k 10

```

### 4.8 Execu√ß√£o ponta‚Äëa‚Äëponta

```
# gerar/atualizar base (opcional)
python coleta_patentes.py
# subir API
python main.py --port 8000
# testar
curl -s http://127.0.0.1:8000/
curl -s -X POST http://127.0.0.1:8000/buscar_similares -H "Content-Type: application/json" -d '{"claims":"Texto das claims","top_k":10}'
# UI
streamlit run streamlit_app.py --server.port 8512

```

---

## 4) Endpoints principais (API)

* **GET /** ‚Üí status: itens na base e se h√≠brido est√° dispon√≠vel.
* **POST /buscar\_similares**

  ```
  { "claims": "texto das claims‚Ä¶", "top_k": 10 }

  ```
* **POST /verificar** (payload completo; usa `claims` se existir)

  ```
  { "titulo":"...", "resumo":"...", "claims":"...", "descricao":"...", "top_k": 10 }

  ```

**Resposta (exemplo):**

```
{
  "resultados": [
    {"lens_id":"140-...-70X","title":"...","link":"https://www.lens.org/lens/patent/140-...-70X","score":0.8245,"similaridade_percentual":82.45,"fonte":"local"}
  ]
}

```

---

## 5) Base local (formato e regra de ouro)

Arquivo \`\` (lista de objetos):

```
{
  "lens_id":"...",
  "title":"...",
  "abstract":"...",
  "claims":"...",
  "description":"...",
  "embedding":[0.0123, -0.0456, ...]  // vetor 768 **L2-normalizado** das claims
}

```

**Sempre salve o embedding das *********************claims********************* j√° L2‚Äënormalizado.**

---

## 6) H√≠brido (Local + Lens) ‚Äî opcional

1. Crie `.env` na raiz:

   ```
   LENS_API_KEY=SEU_TOKEN_DA_LENS

   ```
2. Mantenha `lens_api.py` e `buscar_hibrido.py` na raiz. O servidor tenta h√≠brido e faz **fallback** para Local se falhar.

---

## 7) Requisitos (matriz est√°vel ‚Äî Windows/CPU)

* `torch==2.2.2` + `numpy==1.26.4`
* `transformers==4.41.2` + `tokenizers==0.19.1` + `huggingface-hub==0.23.5`
* `sentence-transformers==2.7.0`
* `fastapi==0.111.0` ¬∑ `starlette==0.37.2` ¬∑ `uvicorn[standard]==0.30.1`
* `streamlit==1.36.0` ¬∑ `scikit-learn==1.5.0`

> Instale o Torch (CPU) **antes** do restante, pelo √≠ndice da PyTorch (comando acima).
> **Arquivo principal de instala√ß√£o**: use `requirements.txt` deste reposit√≥rio para garantir compatibilidade.

---

## 8) Como gerar a base rapidamente

* **CSV/SQL ‚Üí JSON**: extraia `id/title/claims/abstract/description`, calcule `embedding` (claims) com `processamento_texto.gerar_embedding(..., normalize=True)` e salve no formato do item 5.
* **Via Lens**: `python coleta_patentes.py` (respeita `Retry-After`).
* **Reprocessar** embeddings: `python recalcular_embeddings.py`.

---

## 9) Streamlit (UI)

* Modo **Local (JSON)**, **H√≠brido** (se `.env` presente) ou **Via API FastAPI** (aponta para `http://127.0.0.1:8000`).
* Mostra **Top‚ÄëK** com link da Lens e trecho das claims.

---

## 10) Troubleshooting (r√°pido)

* **Porta ocupada**: mude `--server.port` (UI) ou `--port` (API).
* **NumPy/Torch**: use `numpy==1.26.4` com `torch==2.2.2`.
* **Tokenizers/Transformers**: `transformers 4.41.x` requer `tokenizers >=0.19,<0.20` ‚Üí use `0.19.1`.
* **Base vazia**: gere `base_patentes.json` (item 8).

---

## 11) Licen√ßa & aviso

* **Licen√ßa**: defina MIT/Apache‚Äë2.0.
* **Aviso**: ferramenta de apoio √† triagem; n√£o substitui an√°lise t√©cnica/jur√≠dica.

---

## 12) Usar outro banco de dados (local ou API)

Voc√™ **n√£o** est√° preso ao `base_patentes.json`. Qualquer fonte pode ser usada, desde que entregue **texto de claims** e, idealmente, **embeddings L2** no mesmo espa√ßo do modelo.

### A) Outro **arquivo local** (JSON)

1. Converta seu banco para o **esquema do item 5** (chaves e embedding L2 das *claims*).
2. Salve como `base_meu_bd.json`.
3. Altere o caminho no servidor/API:

   * Em `main.py`, troque:

     ```
     BASE_PATH = "base_patentes.json"  # ‚Üí "base_meu_bd.json"

     ```
   * (Se usar busca direta local no app) Em `buscar_similares.py`, troque `CAMINHO_ARQUIVO` para o novo JSON.

> Recomenda-se **exportar para JSON** no formato do item 5. √â simples, r√°pido e reaproveita todo o pipeline.

### B) **CSV/SQL** ‚Üí JSON (convers√£o r√°pida)

Use um adaptador simples para transformar suas tabelas em JSON compat√≠vel:

```
# adapters/csv_para_json.py (exemplo)
import pandas as pd, json
from processamento_texto import gerar_embedding

def csv_para_json(caminho_csv, saida_json):
    df = pd.read_csv(caminho_csv)
    itens = []
    for _, r in df.iterrows():
        claims = str(r.get('claims', '') or '').strip()
        if not claims:
            continue
        emb = gerar_embedding(texto_claims=claims, normalize=True).tolist()
        itens.append({
            "lens_id": str(r.get('id', '')),
            "title": r.get('title', ''),
            "abstract": r.get('abstract', ''),
            "claims": claims,
            "description": r.get('description', ''),
            "embedding": emb
        })
    with open(saida_json, 'w', encoding='utf-8') as f:
        json.dump(itens, f, ensure_ascii=False, indent=2)

```

Depois aponte `BASE_PATH`/`CAMINHO_ARQUIVO` para o JSON gerado.

### C) **Outra API externa** (al√©m da Lens)

Adapte um provedor que retorne **candidatos por claims**, depois **re‚Äëranqueie localmente**:

1. Crie um m√≥dulo do provedor, e.g. `providers/meu_provedor.py`:

   ```
   # providers/meu_provedor.py (exemplo)
   import os, requests
   from dotenv import load_dotenv
   load_dotenv()
   API_KEY = os.getenv("MEU_API_KEY")

   def candidatos_por_claims(texto_claims: str, top_n: int = 30):
       # 1) chame a API e traga candidatos (id, t√≠tulo, claims/trecho, link)
       # 2) normalize campos e retorne lista de dicts compat√≠veis
       # Estrutura m√≠nima por item: {"id":"...","title":"...","claims":"...","link":"..."}
       return []

   ```
2. Inclua no **h√≠brido** (`buscar_hibrido.py`):

   ```
   from providers.meu_provedor import candidatos_por_claims as prov_meu

   PROVEDORES = [
       ("lens", candidatos_por_claims),   # j√° existente
       ("meu",  prov_meu),                # novo provedor
   ]

   todos = []
   for nome, fn in PROVEDORES:
       cands = fn(texto_claims, top_n=top_k*3)
       # calcule embedding localmente e anexe ao pool
       for c in cands:
           emb = gerar_embedding(texto_claims=c.get("claims",""), normalize=True)
           todos.append({
               "lens_id": c.get("id",""),
               "title": c.get("title",""),
               "claims": c.get("claims",""),
               "link": c.get("link",""),
               "embedding": emb.tolist(),
               "fonte": "externa"
           })
   # depois: dedup por lens_id/id, cosine com a query e Top‚ÄëK

   ```
3. Configure a chave no `.env` (ex.: `MEU_API_KEY=...`).

> Dica: se a API externa n√£o fornece **claims** completas, use **resumo/trecho** relevante. O re‚Äëranqueamento local via embedding alinha as escalas.

### D) Observa√ß√µes importantes

* **Consist√™ncia de espa√ßo vetorial**: se trocar o **modelo de embedding**, **recalcule toda a base** para o mesmo espa√ßo (caso contr√°rio, cosine n√£o √© compar√°vel).
* **Tamanho da base**: para bases muito grandes, considere indexadores ANN (FAISS/HNSW) no futuro.
* **Chaves/seguran√ßa**: mantenha credenciais apenas no back‚Äëend e use HTTPS em produ√ß√£o.

---

## 13) Pr√©‚Äërequisitos (ambiente)

* **Python**: 3.10 ou 3.11 recomendados (Windows 10/11 x64). Funciona em Linux/macOS; ajuste instala√ß√£o do Torch conforme plataforma.
* **RAM**: 8 GB m√≠nimo (12‚Äì16 GB recomendado) para trabalhar com bases m√©dias.
* **Disco**: 2‚Äì5 GB livres (modelos + cache + base local). Bases grandes exigem mais.
* **Rede**: necess√°ria para baixar o modelo na 1¬™ execu√ß√£o e para o modo **H√≠brido** (Lens ou outras APIs).
* **Portas**: API padr√£o `8000`, Streamlit `8512` (ajust√°veis).
* **GPU**: opcional; o projeto foi configurado para **CPU**. Para GPU, instale a variante adequada do Torch e teste as vers√µes do stack.

---

## 14) Testes r√°pidos / verifica√ß√£o

### 14.0 Rodar toda a su√≠te

> Execute a partir da **raiz do projeto**. Se seu c√≥digo est√° em `src/`, defina o `PYTHONPATH`.

**Windows (PowerShell):**

```
# ativar venv
. .\.venv\Scripts\activate
# expor src para os testes
$env:PYTHONPATH = "$PWD\src"
# rodar todos os testes em tests/
python -m unittest discover -s tests -p "test_*.py" -v

```

> Dica: na 1¬™ execu√ß√£o o modelo √© baixado; a segunda rodada fica bem mais r√°pida.
> Se n√£o quiser mexer em `PYTHONPATH`, no topo de cada teste voc√™ pode inserir:
>
> ```
> import os, sys
> ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
> SRC  = os.path.join(ROOT, "src")
> for p in (ROOT, SRC):
>     sys.path.insert(0, p) if p not in sys.path else None
>
> ```

### 14.1 Sanidade do modelo

```
python - << 'PY'
from sentence_transformers import SentenceTransformer
import numpy as np
m = SentenceTransformer("paraphrase-multilingual-mpnet-base-v2")
e = m.encode("teste r√°pido", convert_to_numpy=True)
print("shape:", e.shape, "norm:", float(np.linalg.norm(e)))
PY

```

Sa√≠da esperada: `shape: (768,)` e `norm > 0`.

### 14.2 API online

```
# subir API
python main.py --port 8000
# status
curl -s http://127.0.0.1:8000/
# busca
curl -s -X POST http://127.0.0.1:8000/buscar_similares \
  -H "Content-Type: application/json" \
  -d '{"claims":"Um sistema para ...","top_k":10}'

```

> Se seu `main.py` estiver em `src/` e voc√™ preferir usar uvicorn direto:
> `uvicorn src.main:app --host 127.0.0.1 --port 8000`

### 14.3 UI (Streamlit)

```
streamlit run streamlit_app.py --server.port 8512

```

Escolha **Local**, **H√≠brido** (se `.env`) ou **Via API FastAPI**.

### 14.4 Scripts de avalia√ß√£o (se aplic√°vel)

* `similaridade.py`: fun√ß√µes de score (0‚Äì1 para m√©tricas; % para exibi√ß√£o).
* `avaliar_metricas.py`: gera m√©tricas agregadas (precis√£o\@K, etc.).
* `avaliar_pares_manual.py` / `avaliar_pares_rotulados_sem_zona.py`: avaliam pares rotulados.

Exemplo:

```
python avaliar_metricas.py --arquivo rotulos.jsonl --k 10

```

> Observa√ß√£o: os testes e avalia√ß√µes usam **apenas base local**; n√£o chamam a Lens (sem rede).

---

## 15) Exemplo visual

Adicione imagens na pasta `assets/` e referencie aqui:

**UI (Streamlit)**

**Resposta da API**

> Substitua pelos seus prints. No GitHub, arraste as imagens para a pasta `assets/`.

---

## 16) Links √∫teis

* Modelo (Hugging Face): [https://huggingface.co/sentence-transformers/paraphrase-multilingual-mpnet-base-v2](https://huggingface.co/sentence-transformers/paraphrase-multilingual-mpnet-base-v2)
* [Sentence](https://huggingface.co/sentence-transformers/paraphrase-multilingual-mpnet-base-v2)-Transformers (docs): [https://www.sbert.net/](https://www.sbert.net/)
* [Transfor](https://www.sbert.net/)mers (docs): [https://huggingface.co/docs/transformers/index](https://huggingface.co/docs/transformers/index)
* [FastAPI ](https://huggingface.co/docs/transformers/index)(docs): [https://fastapi.tiangolo.com/](https://fastapi.tiangolo.com/)
* [Streamli](https://fastapi.tiangolo.com/)t (docs): [https://docs.streamlit.io/](https://docs.streamlit.io/)
* [Lens API](https://docs.streamlit.io/) (docs): [https://docs.lens.org/](https://docs.lens.org/)

---

## [17) Con](https://docs.lens.org/)tato & contribui√ß√µes

* **D√∫vidas/Sugest√µes**: abra uma *issue* no reposit√≥rio ou envie e‚Äëmail para [**SEU\_EMAIL@exemplo.com**](mailto:SEU_EMAIL@exemplo.com).
* **Contribuir**: fa√ßa um *fork*, crie uma *branch* (`feat/minha-feature`), abra um *PR* com descri√ß√£o objetiva e testes (quando aplic√°vel).

**Resposta da API**

> Substitua pelos seus prints. No GitHub, arraste as imagens para a pasta `assets/`.

---

## 16) Links √∫teis

* Modelo (Hugging Face): [https://huggingface.co/sentence-transformers/paraphrase-multilingual-mpnet-base-v2](https://huggingface.co/sentence-transformers/paraphrase-multilingual-mpnet-base-v2)
* Sentence-Transformers (docs): [https://www.sbert.net/](https://www.sbert.net/)
* Transformers (docs): [https://huggingface.co/docs/transformers/index](https://huggingface.co/docs/transformers/index)
* FastAPI (docs): [https://fastapi.tiangolo.com/](https://fastapi.tiangolo.com/)
* Streamlit (docs): [https://docs.streamlit.io/](https://docs.streamlit.io/)
* Lens API (docs): [https://docs.lens.org/](https://docs.lens.org/)

---

## 17) Contato & contribui√ß√µes

* **D√∫vidas/Sugest√µes**: abra uma *issue* no reposit√≥rio ou envie e‚Äëmail para [isabela.andradeaguiar1@gmail.com](mailto:isabela.andradeaguiar1@gmail.com)\*\*.
* **Contribuir**: fa√ßa um *fork*, crie uma *branch* (`feat/minha-feature`), abra um *PR* com descri√ß√£o objetiva e testes (quando aplic√°vel).
